{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "from utility import parse_config, seed_everything, custom_print\n",
    "from preprocess_class import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/transformers/utils/import_utils.py\", line 1110, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/transformers/trainer.py\", line 168, in <module>\n",
      "    import datasets\n",
      "ModuleNotFoundError: No module named 'datasets'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "  File \"/var/folders/j0/zzt4z9p97ns3p77mp_qltfq40000gn/T/ipykernel_57696/3257931397.py\", line 1, in <module>\n",
      "    from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AdamW, get_linear_schedule_with_warmup\n",
      "  File \"<frozen importlib._bootstrap>\", line 1039, in _handle_fromlist\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/transformers/utils/import_utils.py\", line 1100, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/transformers/utils/import_utils.py\", line 1112, in _get_module\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "No module named 'datasets'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in structured_traceback\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1003, in get_records\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/inspect.py\", line 979, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/Users/gjj980/miniforge3/envs/voc_project/lib/python3.8/inspect.py\", line 798, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "#Trainer arguments\n",
    "\n",
    "# Define the training loop\n",
    "def train(model_name, train_dataset, eval_dataset):\n",
    "    # Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=50,\n",
    "        save_total_limit=5,\n",
    "    )\n",
    "\n",
    "    # Define the optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    num_training_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=training_args.warmup_steps, num_training_steps=num_training_steps)\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=lr_scheduler,\n",
    "        compute_metrics=compute_metrics,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating BERTClassifier class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
