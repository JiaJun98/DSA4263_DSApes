{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from re import sub\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords #trying different stopword list from packages nltk has a small list of stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS #sklearn have larger list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tingy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Remove HTML tags (Done)\n",
    "# 2.Remove extra whitespaces (For leading and trailing)\n",
    "# 3.Convert accented characters to ASCII characters (Not sure if necessary for this data)\n",
    "# 4.Expand contractions (Depending on stopwords used, don't think needed)\n",
    "# 5.Remove special characters (Not sure)\n",
    "# 6.Lowercase all texts (Done)\n",
    "# 7.Convert number words to numeric form (Not yet, probably need)\n",
    "# 8.Remove numbers (Not yet, probably need)\n",
    "# 9.Remove stopwords (Should words like 'not', 'no' be removed or not for sentiment analysis?)\n",
    "# 10.Remove punctuation\n",
    "# 11.Tokenisation (word and sentence)\n",
    "# 12.Lemmatization and stemming(TRY BOTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should split to train, test first before preprocessing for actual model\n",
    "train, test = train_test_split(df, test_size = 0.2, random_state = 4263, stratify = df['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " length:: 1:00 minsthese cookies are so great! watch our video to see how great they really are!!!\n",
      "stores are not carrying this product - thank goodness i can still get them!!!!genisoy soy crisps, deep sea salted, 3.85-ounce bags (pack of 12)\n",
      "length:: 1:00 minsthese cookies are so great! watch our video to see how great they really are!!!\n",
      "stores are not carrying this product - thank goodness i can still get them!!!!genisoy soy crisps, deep sea salted, 3.85-ounce bags (pack of 12)\n"
     ]
    }
   ],
   "source": [
    "#noisy entity removal (HTML tag) eg. </a> <br/? <a href=\"http://www.amazon.com/gp/product/B000CMHMUC\"> + changing all to lowercase\n",
    "print(df.loc[28, 'Text'])\n",
    "print(df.loc[46, 'Text'])\n",
    "df['Text'] = df['Text'].apply(lambda x: sub(\"<[^>]+>\", \"\", x).lower().strip())\n",
    "print(df.loc[28, 'Text'])\n",
    "print(df.loc[46, 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>word_token</th>\n",
       "      <th>sent_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>18/6/21</td>\n",
       "      <td>this is a very healthy dog food. good for thei...</td>\n",
       "      <td>[this, is, a, very, healthy, dog, food, ., goo...</td>\n",
       "      <td>[this is a very healthy dog food., good for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>7/7/21</td>\n",
       "      <td>i've been very pleased with the natural balanc...</td>\n",
       "      <td>[i, 've, been, very, pleased, with, the, natur...</td>\n",
       "      <td>[i've been very pleased with the natural balan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>18/6/21</td>\n",
       "      <td>before i was educated about feline nutrition, ...</td>\n",
       "      <td>[before, i, was, educated, about, feline, nutr...</td>\n",
       "      <td>[before i was educated about feline nutrition,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>7/7/21</td>\n",
       "      <td>my holistic vet recommended this, along with a...</td>\n",
       "      <td>[my, holistic, vet, recommended, this, ,, alon...</td>\n",
       "      <td>[my holistic vet recommended this, along with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1/7/21</td>\n",
       "      <td>i bought this coffee because its much cheaper ...</td>\n",
       "      <td>[i, bought, this, coffee, because, its, much, ...</td>\n",
       "      <td>[i bought this coffee because its much cheaper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5439</th>\n",
       "      <td>negative</td>\n",
       "      <td>26/2/21</td>\n",
       "      <td>this is an okay gift box, only if you like med...</td>\n",
       "      <td>[this, is, an, okay, gift, box, ,, only, if, y...</td>\n",
       "      <td>[this is an okay gift box, only if you like me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>negative</td>\n",
       "      <td>18/12/19</td>\n",
       "      <td>it looks llike i just walked into a raw deal. ...</td>\n",
       "      <td>[it, looks, llike, i, just, walked, into, a, r...</td>\n",
       "      <td>[it looks llike i just walked into a raw deal....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>negative</td>\n",
       "      <td>19/1/20</td>\n",
       "      <td>thank god that i tasted the metal before i swa...</td>\n",
       "      <td>[thank, god, that, i, tasted, the, metal, befo...</td>\n",
       "      <td>[thank god that i tasted the metal before i sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>negative</td>\n",
       "      <td>13/9/20</td>\n",
       "      <td>this product was very good when i began buying...</td>\n",
       "      <td>[this, product, was, very, good, when, i, bega...</td>\n",
       "      <td>[this product was very good when i began buyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>negative</td>\n",
       "      <td>10/7/20</td>\n",
       "      <td>once again, paragon has disappointed with this...</td>\n",
       "      <td>[once, again, ,, paragon, has, disappointed, w...</td>\n",
       "      <td>[once again, paragon has disappointed with thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5444 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment      Time                                               Text  \\\n",
       "0     positive   18/6/21  this is a very healthy dog food. good for thei...   \n",
       "1     positive    7/7/21  i've been very pleased with the natural balanc...   \n",
       "2     positive   18/6/21  before i was educated about feline nutrition, ...   \n",
       "3     positive    7/7/21  my holistic vet recommended this, along with a...   \n",
       "4     positive    1/7/21  i bought this coffee because its much cheaper ...   \n",
       "...        ...       ...                                                ...   \n",
       "5439  negative   26/2/21  this is an okay gift box, only if you like med...   \n",
       "5440  negative  18/12/19  it looks llike i just walked into a raw deal. ...   \n",
       "5441  negative   19/1/20  thank god that i tasted the metal before i swa...   \n",
       "5442  negative   13/9/20  this product was very good when i began buying...   \n",
       "5443  negative   10/7/20  once again, paragon has disappointed with this...   \n",
       "\n",
       "                                             word_token  \\\n",
       "0     [this, is, a, very, healthy, dog, food, ., goo...   \n",
       "1     [i, 've, been, very, pleased, with, the, natur...   \n",
       "2     [before, i, was, educated, about, feline, nutr...   \n",
       "3     [my, holistic, vet, recommended, this, ,, alon...   \n",
       "4     [i, bought, this, coffee, because, its, much, ...   \n",
       "...                                                 ...   \n",
       "5439  [this, is, an, okay, gift, box, ,, only, if, y...   \n",
       "5440  [it, looks, llike, i, just, walked, into, a, r...   \n",
       "5441  [thank, god, that, i, tasted, the, metal, befo...   \n",
       "5442  [this, product, was, very, good, when, i, bega...   \n",
       "5443  [once, again, ,, paragon, has, disappointed, w...   \n",
       "\n",
       "                                             sent_token  \n",
       "0     [this is a very healthy dog food., good for th...  \n",
       "1     [i've been very pleased with the natural balan...  \n",
       "2     [before i was educated about feline nutrition,...  \n",
       "3     [my holistic vet recommended this, along with ...  \n",
       "4     [i bought this coffee because its much cheaper...  \n",
       "...                                                 ...  \n",
       "5439  [this is an okay gift box, only if you like me...  \n",
       "5440  [it looks llike i just walked into a raw deal....  \n",
       "5441  [thank god that i tasted the metal before i sw...  \n",
       "5442  [this product was very good when i began buyin...  \n",
       "5443  [once again, paragon has disappointed with thi...  \n",
       "\n",
       "[5444 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenisation (Word and sentence)\n",
    "#Saw a website saying should tokenise before getting rid of stopwords etc, but I'm not sure about it, can check what order should it be applied?\n",
    "df[\"sent_token\"] = df[\"Text\"].apply(sent_tokenize)\n",
    "df[\"word_token\"] = df[\"Text\"].apply(word_tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "#remove stopwords\n",
    "#Stop word includes words such as 'NO', 'NOT' which might be important for sentiment analysis, how should we approach? remove those stopwords?\n",
    "print(len(stopwords.words('english')))\n",
    "print(len(ENGLISH_STOP_WORDS))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
